{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import ks_1samp, norm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from scipy.stats import ks_2samp, kstest, norm, skew, boxcox\n",
    "import numpy as np\n",
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "from scipy.stats import mstats\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import ParameterGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset.csv\", delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanR</th>\n",
       "      <th>meanG</th>\n",
       "      <th>meanB</th>\n",
       "      <th>stdR</th>\n",
       "      <th>stdG</th>\n",
       "      <th>stdB</th>\n",
       "      <th>skewR</th>\n",
       "      <th>skewG</th>\n",
       "      <th>skewB</th>\n",
       "      <th>kurR</th>\n",
       "      <th>kurG</th>\n",
       "      <th>kurB</th>\n",
       "      <th>entR</th>\n",
       "      <th>entG</th>\n",
       "      <th>entB</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.395776</td>\n",
       "      <td>18.057278</td>\n",
       "      <td>4.548844</td>\n",
       "      <td>40.818315</td>\n",
       "      <td>42.747400</td>\n",
       "      <td>15.235375</td>\n",
       "      <td>2.080558</td>\n",
       "      <td>2.117612</td>\n",
       "      <td>4.194824</td>\n",
       "      <td>2.786645</td>\n",
       "      <td>2.922868</td>\n",
       "      <td>18.932746</td>\n",
       "      <td>11.312396</td>\n",
       "      <td>11.302187</td>\n",
       "      <td>10.864530</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.048930</td>\n",
       "      <td>17.143965</td>\n",
       "      <td>4.285857</td>\n",
       "      <td>41.389466</td>\n",
       "      <td>42.116279</td>\n",
       "      <td>14.243516</td>\n",
       "      <td>2.185737</td>\n",
       "      <td>2.233318</td>\n",
       "      <td>4.195780</td>\n",
       "      <td>3.243245</td>\n",
       "      <td>3.436646</td>\n",
       "      <td>19.700106</td>\n",
       "      <td>11.256998</td>\n",
       "      <td>11.242310</td>\n",
       "      <td>10.867538</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.957301</td>\n",
       "      <td>16.498584</td>\n",
       "      <td>5.082156</td>\n",
       "      <td>48.724795</td>\n",
       "      <td>40.816921</td>\n",
       "      <td>15.203335</td>\n",
       "      <td>2.169338</td>\n",
       "      <td>2.245723</td>\n",
       "      <td>3.863509</td>\n",
       "      <td>3.069086</td>\n",
       "      <td>3.474671</td>\n",
       "      <td>17.313374</td>\n",
       "      <td>11.242156</td>\n",
       "      <td>11.228013</td>\n",
       "      <td>11.041794</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.713066</td>\n",
       "      <td>18.029258</td>\n",
       "      <td>4.707696</td>\n",
       "      <td>47.484912</td>\n",
       "      <td>43.629222</td>\n",
       "      <td>14.230307</td>\n",
       "      <td>2.135099</td>\n",
       "      <td>2.147982</td>\n",
       "      <td>3.987222</td>\n",
       "      <td>2.920590</td>\n",
       "      <td>2.926331</td>\n",
       "      <td>18.956953</td>\n",
       "      <td>11.266421</td>\n",
       "      <td>11.260806</td>\n",
       "      <td>11.034323</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.383914</td>\n",
       "      <td>14.581238</td>\n",
       "      <td>4.632718</td>\n",
       "      <td>46.006665</td>\n",
       "      <td>38.900382</td>\n",
       "      <td>14.446719</td>\n",
       "      <td>2.417031</td>\n",
       "      <td>2.458251</td>\n",
       "      <td>3.903999</td>\n",
       "      <td>4.259136</td>\n",
       "      <td>4.460186</td>\n",
       "      <td>17.438845</td>\n",
       "      <td>11.103429</td>\n",
       "      <td>11.094264</td>\n",
       "      <td>10.944285</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       meanR      meanG     meanB       stdR       stdG       stdB     skewR  \\\n",
       "0  17.395776  18.057278  4.548844  40.818315  42.747400  15.235375  2.080558   \n",
       "1  17.048930  17.143965  4.285857  41.389466  42.116279  14.243516  2.185737   \n",
       "2  19.957301  16.498584  5.082156  48.724795  40.816921  15.203335  2.169338   \n",
       "3  19.713066  18.029258  4.707696  47.484912  43.629222  14.230307  2.135099   \n",
       "4  17.383914  14.581238  4.632718  46.006665  38.900382  14.446719  2.417031   \n",
       "\n",
       "      skewG     skewB      kurR      kurG       kurB       entR       entG  \\\n",
       "0  2.117612  4.194824  2.786645  2.922868  18.932746  11.312396  11.302187   \n",
       "1  2.233318  4.195780  3.243245  3.436646  19.700106  11.256998  11.242310   \n",
       "2  2.245723  3.863509  3.069086  3.474671  17.313374  11.242156  11.228013   \n",
       "3  2.147982  3.987222  2.920590  2.926331  18.956953  11.266421  11.260806   \n",
       "4  2.458251  3.903999  4.259136  4.460186  17.438845  11.103429  11.094264   \n",
       "\n",
       "        entB  Class  \n",
       "0  10.864530      1  \n",
       "1  10.867538      1  \n",
       "2  11.041794      1  \n",
       "3  11.034323      1  \n",
       "4  10.944285      1  "
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"Class\"])\n",
    "y = df[\"Class\"]\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode y to make classes zero-indexed\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Proceed with splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_boxcox_transformation(data):\n",
    "    transformed_data = data.copy()\n",
    "    for col in transformed_data.columns:\n",
    "        if (transformed_data[col] > 0).all():\n",
    "            transformed_data[col], _ = boxcox(transformed_data[col] + 1e-8)\n",
    "    return transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_log_transformation(data):\n",
    "    transformed_data = data.copy()\n",
    "    for col in transformed_data.columns:\n",
    "        if (transformed_data[col] > 0).all():\n",
    "            transformed_data[col] = np.log1p(transformed_data[col])\n",
    "    return transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_sqrt_transformation(data):\n",
    "    transformed_data = data.copy()\n",
    "    for col in transformed_data.columns:\n",
    "        if (transformed_data[col] >= 0).all():\n",
    "            transformed_data[col] = np.sqrt(transformed_data[col])\n",
    "    return transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_yeo_johnson_transformation(data):\n",
    "    transformed_data = data.copy()\n",
    "    numeric_cols = transformed_data.select_dtypes(include=['float64', 'int64']).columns\n",
    "    \n",
    "    # Winsorize outliers\n",
    "    for col in numeric_cols:\n",
    "        transformed_data[col] = mstats.winsorize(transformed_data[col], limits=[0.001, 0.001])\n",
    "\n",
    "    # Apply log transformation\n",
    "    transformed_data[numeric_cols] = transformed_data[numeric_cols].apply(np.log1p)\n",
    "\n",
    "    # Apply Yeo-Johnson Power Transform\n",
    "    pt = PowerTransformer(method='yeo-johnson')\n",
    "    transformed_data[numeric_cols] = pt.fit_transform(transformed_data[numeric_cols])\n",
    "    \n",
    "    return transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for Combined Transformations (Box-Cox -> Log -> Sqrt -> Yeo-Johnson)\n",
    "def apply_combined_transformations(data):\n",
    "    transformed_data = data.copy()\n",
    "    data_boxcox = apply_boxcox_transformation(transformed_data)\n",
    "    data_log = apply_log_transformation(data_boxcox)\n",
    "    data_sqrt = apply_sqrt_transformation(data_log)\n",
    "    data_yeo_johnson = apply_yeo_johnson_transformation(data_sqrt)\n",
    "    return data_yeo_johnson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Apply Combined Transformations to X_train and X_test\n",
    "X_train_combination = apply_combined_transformations(X_train)\n",
    "X_test_combination = apply_combined_transformations(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define parameter grids\n",
    "# logistic_params = {\n",
    "#     \"penalty\": [\"l1\"],\n",
    "#     \"C\": [0.1],\n",
    "#     \"solver\": [\"liblinear\"],\n",
    "#     \"max_iter\": [1000],\n",
    "# }\n",
    "\n",
    "# xgboost_params = {\n",
    "#     \"learning_rate\": [0.1],\n",
    "#     \"n_estimators\": [100],\n",
    "#     \"max_depth\": [5],\n",
    "# }\n",
    "\n",
    "# # Combine stacking parameters\n",
    "# stacking_params = {\n",
    "#     \"logistic__penalty\": logistic_params[\"penalty\"],\n",
    "#     \"logistic__C\": logistic_params[\"C\"],\n",
    "#     \"logistic__solver\": logistic_params[\"solver\"],\n",
    "#     \"logistic__max_iter\": logistic_params[\"max_iter\"],\n",
    "#     \"xgboost__learning_rate\": xgboost_params[\"learning_rate\"],\n",
    "#     \"xgboost__n_estimators\": xgboost_params[\"n_estimators\"],\n",
    "#     \"xgboost__max_depth\": xgboost_params[\"max_depth\"],\n",
    "#     \"final_estimator__C\": [0.1],\n",
    "#     \"final_estimator__max_iter\": [1000],\n",
    "# }\n",
    "\n",
    "# # Initialize models\n",
    "# logistic_model = LogisticRegression(random_state=42)\n",
    "# xgboost_model = xgb.XGBClassifier(eval_metric=\"logloss\", random_state=42)\n",
    "\n",
    "# # StackingClassifier setup\n",
    "# stacking_model = StackingClassifier(\n",
    "#     estimators=[\n",
    "#         (\"logistic\", LogisticRegression(random_state=42)),\n",
    "#         (\"xgboost\", xgb.XGBClassifier(eval_metric=\"logloss\", random_state=42)),\n",
    "#     ],\n",
    "#     final_estimator=LogisticRegression(random_state=42),\n",
    "# )\n",
    "\n",
    "# # Define scoring metrics for multiclass problems\n",
    "\n",
    "# # Perform grid search for each model\n",
    "# results = []\n",
    "\n",
    "# def evaluate_model_multiple_runs(name, model, X_train, y_train, X_test, y_test, param_grid, n_runs=1):\n",
    "#     grid_search = GridSearchCV(\n",
    "#         model,\n",
    "#         param_grid,\n",
    "#         refit=\"accuracy\",  # Refits using the best model based on accuracy\n",
    "#         cv=2,\n",
    "#         verbose=1\n",
    "#     )\n",
    "#     grid_search.fit(X_train, y_train)\n",
    "\n",
    "#     best_params = grid_search.best_params_\n",
    "\n",
    "#     # Refit the best model n_runs times and log metrics\n",
    "#     for run in range(1, n_runs + 1):\n",
    "#         best_model = grid_search.best_estimator_\n",
    "#         best_model.fit(X_train, y_train)\n",
    "#         y_pred = best_model.predict(X_test)\n",
    "\n",
    "#         # Get class-wise metrics\n",
    "#         class_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "#         # Initialize dictionary for each run\n",
    "#         metrics = {\n",
    "#             \"run_number\": run,\n",
    "#             \"method\": name,\n",
    "#             \"parameters\": best_params,\n",
    "#         }\n",
    "\n",
    "#         # Add global metrics like accuracy\n",
    "#         metrics[\"accuracy\"] = class_report[\"accuracy\"]\n",
    "\n",
    "#         # Add per-class metrics as separate columns\n",
    "#         for label, label_metrics in class_report.items():\n",
    "#             if isinstance(label_metrics, dict):  # Ignore global rows like \"accuracy\"\n",
    "#                 metrics[f\"precision_class_{label}\"] = label_metrics[\"precision\"]\n",
    "#                 metrics[f\"recall_class_{label}\"] = label_metrics[\"recall\"]\n",
    "#                 metrics[f\"f1_class_{label}\"] = label_metrics[\"f1-score\"]\n",
    "#                 metrics[f\"support_class_{label}\"] = label_metrics[\"support\"]\n",
    "\n",
    "#         # Append results\n",
    "#         results.append(metrics)\n",
    "\n",
    "# # Evaluate Logistic Regression\n",
    "# evaluate_model_multiple_runs(\"Logistic Regression\", logistic_model, X_train_combination, y_train, X_test_combination, y_test, logistic_params)\n",
    "\n",
    "# # Evaluate XGBoost\n",
    "# evaluate_model_multiple_runs(\"XGBoost\", xgboost_model, X_train_combination, y_train, X_test_combination, y_test, xgboost_params)\n",
    "\n",
    "# # Evaluate Stacking Classifier\n",
    "# evaluate_model_multiple_runs(\"Stacking\", stacking_model, X_train_combination, y_train, X_test_combination, y_test, stacking_params)\n",
    "\n",
    "# # Convert results to DataFrame\n",
    "# results_df = pd.DataFrame(results)\n",
    "\n",
    "# # Save results to CSV if needed\n",
    "# results_df.to_csv(\"grid_search_results_with_runs.csv\", index=False)\n",
    "\n",
    "# results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# Define parameter grids\n",
    "logistic_params = {\n",
    "    # \"penalty\": [\"l1\", \"l2\"],  # Adding l2 penalty\n",
    "    # \"C\": [0.01, 0.1, 1, 10],  # Testing a wider range of regularization strengths\n",
    "    # \"solver\": [\"liblinear\"],  # Keeping solver fixed\n",
    "    \"max_iter\": [1000],  # Keeping max_iter constant\n",
    "}\n",
    "\n",
    "xgboost_params = {\n",
    "    \"learning_rate\": [0.01, 0.1, 0.2],  # Testing multiple learning rates\n",
    "    \"n_estimators\": [50, 100, 200],  # Testing a wider range of estimators\n",
    "    \"max_depth\": [3, 5, 7],  # Testing additional tree depths\n",
    "}\n",
    "\n",
    "# Combine stacking parameters\n",
    "stacking_params = {\n",
    "    # \"logistic__penalty\": logistic_params[\"penalty\"],\n",
    "    # \"logistic__C\": logistic_params[\"C\"],\n",
    "    # \"logistic__solver\": logistic_params[\"solver\"],\n",
    "    \"logistic__max_iter\": logistic_params[\"max_iter\"],\n",
    "    \"xgboost__learning_rate\": xgboost_params[\"learning_rate\"],\n",
    "    \"xgboost__n_estimators\": xgboost_params[\"n_estimators\"],\n",
    "    \"xgboost__max_depth\": xgboost_params[\"max_depth\"],\n",
    "    \"final_estimator__max_iter\": [1000],\n",
    "}\n",
    "\n",
    "# Initialize models\n",
    "logistic_model = LogisticRegression(random_state=42)\n",
    "xgboost_model = xgb.XGBClassifier(eval_metric=\"logloss\", random_state=42)\n",
    "\n",
    "# StackingClassifier setup\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=[\n",
    "        (\"logistic\", LogisticRegression(random_state=42)),\n",
    "        (\"xgboost\", xgb.XGBClassifier(eval_metric=\"logloss\", random_state=42)),\n",
    "    ],\n",
    "    final_estimator=LogisticRegression(random_state=42),\n",
    ")\n",
    "\n",
    "def evaluate_model_separate_training(name, model, X_train, y_train, X_test, y_test, param_grid, n_runs=5):\n",
    "    results = []\n",
    "    \n",
    "    # Iterate over all parameter combinations using ParameterGrid\n",
    "    for params in ParameterGrid(param_grid):\n",
    "        # Set parameters to the model\n",
    "        model.set_params(**params)\n",
    "        \n",
    "        # Fit the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Evaluate over multiple runs\n",
    "        for run in range(1, n_runs + 1):\n",
    "            y_pred = model.predict(X_test)\n",
    "            \n",
    "            # Get class-wise metrics\n",
    "            class_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "            \n",
    "            # Initialize dictionary for each run\n",
    "            metrics = {\n",
    "                \"run_number\": run,\n",
    "                \"method\": name,\n",
    "                **params,  # Unpack current parameters into the metrics dictionary\n",
    "            }\n",
    "            \n",
    "            print(run)\n",
    "            \n",
    "            # Add global metrics like accuracy\n",
    "            metrics[\"accuracy\"] = class_report[\"accuracy\"]\n",
    "            \n",
    "            # Add per-class metrics as separate columns\n",
    "            for label, label_metrics in class_report.items():\n",
    "                if isinstance(label_metrics, dict):  # Ignore global rows like \"accuracy\"\n",
    "                    metrics[f\"precision_class_{label}\"] = label_metrics.get(\"precision\", 0)\n",
    "                    metrics[f\"recall_class_{label}\"] = label_metrics.get(\"recall\", 0)\n",
    "                    metrics[f\"f1_class_{label}\"] = label_metrics.get(\"f1-score\", 0)\n",
    "                    metrics[f\"support_class_{label}\"] = label_metrics.get(\"support\", 0)\n",
    "            \n",
    "            # Append results\n",
    "            results.append(metrics)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Evaluate Stacking Classifier\n",
    "stacking_results = evaluate_model_separate_training(\n",
    "    \"Stacking\",\n",
    "    stacking_model,\n",
    "    X_train_combination,\n",
    "    y_train,\n",
    "    X_test_combination,\n",
    "    y_test,\n",
    "    stacking_params\n",
    ")\n",
    "\n",
    "# Save results to an Excel file\n",
    "stacking_results_df = pd.DataFrame(stacking_results)\n",
    "stacking_results_df.to_excel(\"stacking_results.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
